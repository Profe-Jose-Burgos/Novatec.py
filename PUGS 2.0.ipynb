{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40055ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lematizar = SnowballStemmer('spanish')\n",
    "palabras = [stemmer.stem(w_token()) for w_token in palabras if w_token not in palabras_ignoradas] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfbe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(palabras, open(\"palabras.pkl\", \"wb\"))\n",
    "pickle.dump(categorias, open(\"categorias.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d331d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento = []\n",
    "\n",
    "salida_vac = [0]*len(categorias)\n",
    "\n",
    "for d in documentos:\n",
    "    contenedor = []\n",
    "    patrones_pal = d[0]\n",
    "    patrones_pal = [lematizar.stem(word.lower()) for palabras in patrones_pal if palabras not in palabras_ignoradas]\n",
    "    \n",
    "    for p in palabras:\n",
    "        contenedor.append(1) if palabra in patrones_pal else contenedor.append(0)\n",
    "        \n",
    "    salida_num = list(salida_vac)   \n",
    "    salida_num[categorias.index(d[1])]=1\n",
    "    entrenamiento.append([contenedor,salida_num])\n",
    "\n",
    "entrenamiento=np.array(entrenamiento)\n",
    "\n",
    "x_train = list(entrenamiento[:,0])\n",
    "y_train = list(entrenamiento[:,1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
